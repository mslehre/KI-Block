{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "411bf9c8-a8da-4c66-8fb8-e3981cd3351b",
   "metadata": {},
   "source": [
    "# Sequence classification using CNNs\n",
    "\n",
    "Welcome the sequence classification. In the next few hours, we will go through three notebooks in which you will learn how to classify RNA sequences using Convolutional Neural Networks (CNNs).\n",
    "\n",
    "**BEFORE WE START**: Make sure you have **10 GB of RAM** (check the \"Mem:\" bar in the upper right corner of this screen). If you have less, please go to the AppHub page, choose Data Science > Advanced > RAM and set the Slider to 10 GiB, then restart your server. \n",
    "\n",
    "Key Points:\n",
    "\n",
    "**1_data_processing**: Read in the data; Visualize sequence properties; Create 'naive' baseline predictions;\n",
    "\n",
    "**2_cnn_classification**: Compare different input transformation; Classify sequences using simple CNNs; Cross-validate results; Use Grid-Search for model optimization; \n",
    "\n",
    "**3_cnn_classification_structure**: Using secondary structure for prediction; Combining sequence and structure information with Early and Late Integration;\n",
    "\n",
    "Throughout the notebooks you will need to fill in blanks. These will be marked using XXXX and usually marked with a comment, what you need to fill in this spot.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# 1 Data Processing to generate sequence files for our CNN\n",
    "\n",
    "## Read in the sequence data\n",
    "\n",
    "We want to classify snoRNA families (C/D-box and H/ACA-box) as well as the related scaRNA family using the nucleotide sequences consisting of A,C,G and T. Nucleotide sequences are usually saved in a file format called \".fasta\". A fasta file is defined by a header line starting with \">\" and one or multiple lines of nucelotide sequence until the next header starts.\n",
    "\n",
    "`>sequence_id description`\n",
    "\n",
    "`nucleotide sequence`\n",
    "\n",
    "For Example:\n",
    "\n",
    "`>URS0000A97CA8_9358 snoRNA`\n",
    "\n",
    "`CGGGCCCTGAATCAGGACCAGTAGTTTGCTGTATCGTTAGTTTTAAAAAAGAGCCAAGAG`\n",
    "\n",
    "`CTAATTCTTCTTATGATTGGCTATTCAGTACCATAGTAAGGAATGGCCCCTTCATTTGGA`\n",
    "\n",
    "`AAAAACAGTC`\n",
    "\n",
    "As we need to preprocess our input before we can train or validate our machine learning models like Convolutional Neural Networks we have to import the data. First, we will have to read in the data using BioPython's method `SeqIO.parse()`. The sequences should be saved in a dictionary, where the key is the RNAcentral ID from the header and the value is the nucleotide sequence, saved as a string and turned to upper case letters. We do this for all sequences in the fasta file. \n",
    "\n",
    "Next, we will transform our dictionary into a dataframe, using pandas `DataFrame.from_dict()` method. Make sure you orient the dataframe by index and name the column \"sequence\". \n",
    "\n",
    "Do these steps for all three fasta files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2273ba12-3688-48cb-8ebb-c8303bf68a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "haca_dict = {}  # Create an empty dictionary for our sequences\n",
    "\n",
    "fasta_input = SeqIO.parse(\"haca_sequences.fasta\", \"fasta\")  # Read in the HACA sequences using Biopython\n",
    "\n",
    "for rec in fasta_input:  # Iterate over every entry (called record) in the input\n",
    "    \n",
    "    sequence_identifier = rec.id  # Read in the sequence identifier (in the fasta file )\n",
    "    \n",
    "    sequence = [str(rec.seq)]  # Save the sequence. rec.seq is a sequence object from Biopython, but we want to save it as a list containing a string\n",
    "    \n",
    "    haca_dict[sequence_identifier] = sequence  # Enter the record into the dictionary; the sequence identifier is the key, the sequence is the value "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076be3b1-dd4d-4e20-8d25-c06fdbcd8be2",
   "metadata": {},
   "source": [
    "Dictionaries are neat, but for better data transformation/visualization it is often helpful to use Pandas dataframes\n",
    "\n",
    "Lets import Pandas and transform our dictionary using `from_dict()`. We will orient by index (this means one sample corresponds to one row) and name the column \"sequence\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec1bfb-71f3-42e4-ae73-dc7560df52cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # ignore this; Pandas has some warnings that will come up later, that do not matter to us \n",
    "\n",
    "# Transform the dictionary into a dataframe\n",
    "haca_df = pd.DataFrame.from_dict(haca_dict, orient=\"index\", columns=[\"sequence\"])\n",
    "\n",
    "haca_df  # Look at the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4626bf5-70f7-42a1-8b17-7c0c21fffd73",
   "metadata": {},
   "source": [
    "To read in the dictionary in a single line, we can use dictionary comprehension. This does not change the functionality, but reduces the code to a single line. If you want to read more about dictionary comprehension, you can read [this guide](https://www.datacamp.com/tutorial/python-dictionary-comprehension). We will use this, to read in now the second class of snoRNAs (C/D-Box sequences). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ffbe61-b443-467c-8776-ddcbb225a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in sequences as a dictionary\n",
    "cd_dict = {rec.id: [str(rec.seq)] for rec in SeqIO.parse(\"cd_sequences.fasta\", \"fasta\")}\n",
    "\n",
    "# Transform dict into dataframe\n",
    "cd_df = pd.DataFrame.from_dict(cd_dict, orient=\"index\", columns=[\"sequence\"])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e944ecc-29a6-4882-9a91-6d949a976f15",
   "metadata": {},
   "source": [
    "Do the same for scaRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bfac67-2351-42fa-939b-78a6deed6ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the sequences for scaRNA\n",
    "scarna_dict = {rec.id: [str(rec.seq)] for rec in SeqIO.parse(\"scarna_sequences.fasta\", \"fasta\")}  \n",
    "\n",
    "# Transform dict into a dataframe like above\n",
    "scarna_df = pd.DataFrame.from_dict(XXXX)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad197a8-d524-437c-b956-ca36bd2b8de6",
   "metadata": {},
   "source": [
    "Let's see, how many sequences we have of each type.\n",
    "\n",
    "One neat way to print variables are the so called [f-strings](https://www.geeksforgeeks.org/formatted-string-literals-f-strings-python/).\n",
    "\n",
    "If you write f before a string, you can put variables in curly brackets in the string and they are automatically filled with the value of the variable (or any transformations of it you've done within the brackets).\n",
    "\n",
    "Example: \n",
    "\n",
    "`var = 12`\n",
    "\n",
    "`print(f\"{var} people have {2*var} legs!\")`\n",
    "\n",
    "Output:\n",
    "\n",
    "`12 people have 24 legs!`\n",
    "\n",
    "Print the number of sequences using f-strings. Since one entry in the dataframe corresponds to one sequence, the number of sequences is the length of each dataframe, let's use the `len()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da24aca3-6abb-47e4-9667-8ad010ddc061",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of H/ACA-Box sequences: {len(haca_df)}\")\n",
    "print(f\"Number of C/D-Box sequences: {XXXX}\")  # Print the length of the C/D-Box dataframe\n",
    "print(f\"Number of scaRNA sequences: {XXXX}\")  # Print the length of the scaRNA dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6db6a2-a8b5-4c0c-808a-c1b9f4cbbf91",
   "metadata": {},
   "source": [
    "**What special observation can you notice so far from our dataset? Can we directly use it for our CNN?**\n",
    "\n",
    "We are done with processing the three ncRNA classes individually and now want to concatenate them into one big dataframe using `pd.concat()`.\n",
    "Before we do that, we must ensure, that we still know the type of snoRNA for each sequence to have a label for our training dataset. \n",
    "To set a column with the same value for every entry, you can simply do the following:\n",
    "\n",
    "`df[\"column\"] = \"value\"`\n",
    "\n",
    "Give each of our three dataframes a \"type\" column, where you enter the name of each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3922b6b-2f6a-4abf-b1ac-1192a3e16ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the type into a column for each df\n",
    "haca_df[\"type\"] = \"HACA-Box\"\n",
    "cd_df[\"type\"] = \"CD-Box\"\n",
    "scarna_df[\"type\"] = \"scaRNA\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff04562-fde7-4c20-9c94-ff03bd641ed1",
   "metadata": {},
   "source": [
    "Since our dataframes all have the same columns (\"sequence\" and \"type\"), we can simply use `pd.concat()` to create one dataframe. \n",
    "\n",
    "Also, save this dataframe using `.to_csv()` so we can use it in the next notebook again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cdbdaf-042b-43bb-83bc-c4fa34c257ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Concat into a full dataframe\n",
    "full_df = pd.concat([haca_df, cd_df, scarna_df])\n",
    "\n",
    "# Save dataframe to CSV for later\n",
    "full_df.to_csv(\"full_df.csv\", index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb8f29c-a063-4941-ab69-8f9f938acb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3928dca0-a0fe-48d6-84f3-b740dc447f80",
   "metadata": {},
   "source": [
    "### Find sequence features for comparison\n",
    "\n",
    "So far, we only know the id, the type and the nucleotide sequence for each sample. In any classification problem, it is important to look at the data first, to see if you can already spot clear differences between the samples. Looking at nucleotide sequences is not really useful though. Let's create a new column in our dataframe, where we save the length of each sequence.\n",
    "\n",
    "Next, we will add two more columns to our dataframe including sequence features. Such features are commonly used also for images by extracting specific features from the images like specific shapes or light intensity etc.. In our case we will use standard sequence features, which have an influence on the function of the sequence to some extent. To add additional information like the sequence length (\"length\") we will use the `.map()` method. Further features are the composition of the sequence by counting the amount of Guanin (G) and Cytosin (C) or the ratio of GC to AT.\n",
    "\n",
    "To create a new column from another column, you can use the `.map()` function in python. It applies a function to every element of an iterable (in our case a list). The `len()` function that we used earlier for finding the number of sequences can also be used to find the length of a string. Let's map it to the sequence column. This new column will be called \"length\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1297d7b-c81d-47c6-b25f-08f44f9d5fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"length\" column from the sequence length\n",
    "full_df[\"length\"] = full_df[\"sequence\"].map(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfe81ed-5963-478a-8507-ac0f0acf50c9",
   "metadata": {},
   "source": [
    "One way to get an idea of what the data looks like is pandas' `.describe()` method. Let's use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd341e62-afab-4c8a-83ea-3aaadc9ae337",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1906e52-21fe-49c2-bb03-1837a97fd94f",
   "metadata": {},
   "source": [
    "These numbers can give an idea about the distribution, but a plot will always be more accessible. Let's plot the length using Seaborn's `sns.boxplot()` method. `y` is the name of the column that we want to plot on the y-axis, so `\"length\"` and `data` is the name of the dataframe. You can find the documentation of the method [here](https://seaborn.pydata.org/generated/seaborn.boxplot.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be24f9a-1720-498d-805c-0275419384ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# This is needed to make sure the plots are plotted within the notebook\n",
    "%matplotlib inline  \n",
    "\n",
    "sns.boxplot(y=\"length\", data=full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93f9e10-992a-43c2-ae14-04975e7933e1",
   "metadata": {},
   "source": [
    "We can see, that the length is quite variable, but the majority appears to be between 100 and 150 nucleotides. \n",
    "\n",
    "Let's create the same plot again, but this time split the data among the x-axis into the three group. Simply use the same call from above, but pass `x=\"type\"` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22038b78-1b21-4164-a25a-783a436762ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"type\", y=XXXX, data=XXXX)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a117de6a-94f8-441b-a6bd-49eb7e9827a1",
   "metadata": {},
   "source": [
    "\n",
    "For the GC content, use the following formula: $GC(sequence) = (#G + #C) / length(sequence)$. The formula for the ATGC ratio is as following: $ATGC(sequence) = (#A + #T) / (#G + #C)$.\n",
    "Again, we will use the `map()` function, but this time, we will have to create a `lambda` function, as there are no built-in functions to determine the two properties.\n",
    "\n",
    "`lambda` functions are a neat way to create small temporary functions in a single line. They might appear a little tricky at first, but are very useful if used correctly. They work like this:\n",
    "\n",
    "`lambda x: perform your function here`\n",
    "\n",
    "Example: \n",
    "\n",
    "`full_df[\"sequence\"].map(lambda x: len(x)*2+10)`\n",
    "\n",
    "would create a new list with the length of each sequence multiplied by 2 and then increased by 10. Read more about lambda functions [here](https://www.w3schools.com/python/python_lambda.asp).\n",
    "\n",
    "Let's create a lambda function that counts \"G\" and \"C\", adds them together, and then divides the result by the length. You can count the instances using the `.count()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f839a74-027c-4db5-8d6f-7806281218e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GC_content column by counting G and C and dividing their sum by the length\n",
    "full_df[\"GC_content\"] = full_df[\"sequence\"].map(lambda x: (x.count(\"G\") + x.count(\"C\")) / len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ce79f7-1ebe-4357-961f-dce9d14abb23",
   "metadata": {},
   "source": [
    "Let's look at the data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c82558-1288-47a5-8ee3-f7b8bef18e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"type\", y=\"GC_content\", data=full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd3ece-ab7b-4b47-8225-d32fbb7a76d3",
   "metadata": {},
   "source": [
    "Repeat the same for the ATGC ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22a7c29-8180-4ac0-90a2-3ee1c48a382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ATGC_ratio column by counting A+T and dividing by G+C\n",
    "full_df[\"ATGC_ratio\"] = full_df[\"sequence\"].map(lambda x: XXXX)  # create a function that calculates (#A + #T)/(#G + #C)\n",
    "sns.boxplot(x=\"type\", y=\"ATGC_ratio\", data=full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6627217a-e966-45af-b933-7b616c556659",
   "metadata": {},
   "source": [
    "### Let's plot our new properties combined\n",
    "\n",
    "First, let's look at the plot of the combination of these features. Luckily, Seaborn's `pairplot()` method ([documentation](https://seaborn.pydata.org/generated/seaborn.pairplot.html)) does just what we need. We will add the dataframe, but only look at two classes at the time such that differences are more obvious. Let's start with CD and HACA. Make sure you add `hue=\"type\"`, so that the different types will have different colors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df59826-ea0e-45d5-ab16-00e6e4eff1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(full_df.loc[(full_df.type != \"scaRNA\")], hue=\"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65080f5f-db1a-43e9-b83c-93a5f5753013",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(full_df.loc[(full_df.type != \"HACA-Box\")], hue=\"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdae16ba-9fc6-4976-adfd-12962c0dd077",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(full_df.loc[(full_df.type != \"CD-Box\")], hue=\"type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d500b953-2f4b-4fc8-91e2-ad7c7d023361",
   "metadata": {},
   "source": [
    "\n",
    "**Now we have some sequence features extracted and performed visual inspection of pairs of classes. What are your observations? Can you imagine some problems for our ML model later?**\n",
    "\n",
    "Next we will try to find a baseline prediction, meaning how good can be a simple naive model using such features to predict the snoRNA and scaRNA classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2ae360-0d2b-486f-8b49-69b7d784911b",
   "metadata": {},
   "source": [
    "### Creating a baseline how good ncRNA classification is by naive Bayes using the sequence properties\n",
    "\n",
    "To split our data into train and test, we can use the `train_test_split()` method from [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) .\n",
    "\n",
    "The method outputs for things, X_train, X_test, Y_train and Y_test. \n",
    "X_train and X_test are the inputs for our models, in our case `full_df[[\"length\"]]`* split into an 85%/15% ratio. Y_train and Y_test are the corresponding labels that we want our model to output. Since we want to classify by snoRNA type, the output is created from `full_df[\"type\"]`. \n",
    "\n",
    "`test_size` needs to be set to 0.15 for a 85/15 split. `random_state` is the seed for the randomization. Set it to your favorite number. **NOTE: Make sure you always set the random_state to the same number whenever you split data into train and test. Otherwise, changes in the prediction might by attributed to different train/test splits**. Lastly, set `stratify` to the \"type\" column, such that all classes are distributed evenly by their type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91328b37-ba87-4e6c-8de1-735729590dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the training data for length into train and test set\n",
    "X_train_length, X_test_length, Y_train, Y_test = train_test_split(full_df[[\"length\"]],\n",
    "                                                                  full_df[\"type\"],\n",
    "                                                                  test_size=0.15,\n",
    "                                                                  random_state=XXXX, # Set random_state to your favorite number\n",
    "                                                                  stratify=full_df[\"type\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c542718a-0e02-42d1-8853-e40ad7f5a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a dataframe with the number of samples of each class in train und test\n",
    "train_test = pd.DataFrame({'Train': [list(Y_train).count(\"CD-Box\"), list(Y_train).count(\"HACA-Box\"),list(Y_train).count(\"scaRNA\")],\n",
    "                           'Test': [list(Y_test).count(\"CD-Box\"), list(Y_test).count(\"HACA-Box\"), list(Y_test).count(\"scaRNA\")]},\n",
    "                           index=['CD-Box', 'HACA-Box', 'scaRNA'])\n",
    "\n",
    "# Plot in a barplot\n",
    "train_test.plot(kind='bar', stacked=True, color=['blue', 'lightblue'])\n",
    "\n",
    "plt.xlabel('RNA type')\n",
    "plt.ylabel('Number of Sequences')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643e19ea-aa8f-4caa-a10e-5a02792d0c11",
   "metadata": {},
   "source": [
    "Now, we are ready to create our first predictor but it will be not based on the sequence itself but extracted sequence features. \n",
    "\n",
    "Let's classify the sequences using [Naive Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier). Naive Bayes are very simple probabilistic classifiers. The model is trained on a so-called training set and then tested on a small subset of the data, which the model has never seen, the test set.\n",
    "\n",
    "Import GaussianNB and create a classifier. We will try to train it on length first. Create an instant and then train it on the `\"length\"` column* of X_train using the `.fit()` method. We will also need to provide the Y_train vector, so the model knows what the correct labels are.\n",
    "\n",
    "*NOTE: GaussianNB requires the input to be a dataframe. This means, instead of providing the column with `X_train[\"length\"]`, you will have to use `X_train[[\"length\"]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63da96f5-0e2f-4668-9183-45e055bd03cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb_length = GaussianNB() # create classifier\n",
    "gnb_length.fit(X_train_length, Y_train) # train using only length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4b9a09-cf7c-41b5-8154-2ce17bd5d374",
   "metadata": {},
   "source": [
    "Predict the test set using the `.predict()` method and `X_test[[\"length\"]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d68c95-55eb-4bf7-a11a-f6546d1d5f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_length = gnb_length.predict(X_test_length) # generate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67bb529-6baa-48bc-b6e8-34757164b10f",
   "metadata": {},
   "source": [
    "Great! We created our first prediction. But how good is it? Let's look at the accuracy of our model. For this, we will import scikit-learn's `accuracy_score` metric. You can find how to calculate accuracy [here!](https://en.wikipedia.org/wiki/Accuracy_and_precision). We will first need to pass Y_test and then our prediction to the method. Afterwards, print the variable using an f-string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ae8428-2822-4c03-a205-63b7bad9092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Determine the accuracy of the prediction\n",
    "accuracy_length = accuracy_score(Y_test, prediction_length)\n",
    "\n",
    "# Print out the accuracy\n",
    "print(f\"The accuracy for Naive Bayes using length content is {accuracy_length}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab12b78-838c-425e-918a-b0c8564c6ffe",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now we can try to compare it to the other sequence features we extracted like GC content or AT/GC ratio. Let's compare our prediction accuracy. See the code and let it run for GC_content. Use the following three empty boxes to do the same for the AT/GC ratio.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d40365-f56a-415f-99cb-a165677d926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Train and Test for the GC_content. Make sure you set random_state to the same number as before\n",
    "X_train_gc, X_test_gc, Y_train, Y_test = train_test_split(full_df[[\"GC_content\"]], full_df[\"type\"], test_size=0.15, random_state=XXXX, stratify=full_df[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c93804-a904-4d5f-a3e3-0d31a5097c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_gc = GaussianNB() # create classifier\n",
    "gnb_gc.fit(X_train_gc, Y_train) # train using only GC content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec8064c-5886-4a48-90f4-052e78b88ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the GC_content test set\n",
    "prediction_gc = XXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc5731-3405-4b88-9603-31bd6b5b7797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and output the prediction\n",
    "accuracy_gc = accuracy_score(Y_test, prediction_gc)\n",
    "print(f\"The accuracy for Naive Bayes using GC content is {accuracy_gc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02de4408-8e62-4a75-a1e4-19416396eae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Train and Test for the ATGC_ratio. Make sure you set random_state to the same number as before\n",
    "X_train_atgc, X_test_atgc, Y_train, Y_test = XXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259c6ebf-c68d-45c0-bbc7-59e932c1354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the predictor and fit to the test data\n",
    "gnb_atgc = XXXX\n",
    "gnb_atgc.fit(XXXX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69362863-10a2-4947-844a-6452daf79688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test data\n",
    "prediction_atgc = XXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3e940c-1e13-41ba-aae0-452d33e3b7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and output the accuracy\n",
    "accuracy_atgc = XXXX\n",
    "print(f\"The accuracy for Naive Bayes using AT/GC ration is {XXXX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9719bb-9ff3-4a14-925a-212fe566e20e",
   "metadata": {},
   "source": [
    "### Look at the results in more detail\n",
    "\n",
    "Accuracy gives a good general idea, how well a model performs, but what if we want to know individual results for each class? Scikit-learn provides a neat method for this called `classification_report()` ([Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)). It outputs class-wise as well as over all [Precision, Recall](https://en.wikipedia.org/wiki/Precision_and_recall) and [F1-score](https://en.wikipedia.org/wiki/F-score).\n",
    "\n",
    "Let's look at the classification report for our highest scoring prediction using just length (`prediction_length`). \n",
    "\n",
    "Additionally, we will save F1-score, Precision and Recall for each model, so we can compare all scores in the end in a single plot. \n",
    "\n",
    "Note, that these measures require that you used the same random state for each train/test split, so if you used different ones then set them to the same and rerun, such that the results are comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5b25a6-f699-42b2-be36-ee42f5f1e9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Print classifcation report\n",
    "print(classification_report(Y_test, prediction_length))\n",
    "\n",
    "# Save scores for later\n",
    "f1_length = f1_score(Y_test, prediction_length, average=\"weighted\")\n",
    "prec_length = precision_score(Y_test, prediction_length, average=\"weighted\")\n",
    "rec_length = recall_score(Y_test, prediction_length, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a38bf4-564f-462d-a573-742eacf729bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(classification_report(Y_test, prediction_gc))\n",
    "\n",
    "# Save scres for later\n",
    "f1_gc = f1_score(Y_test, prediction_gc, average=\"weighted\")\n",
    "prec_gc = precision_score(Y_test, prediction_gc, average=\"weighted\")\n",
    "rec_gc = recall_score(Y_test, prediction_gc, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302d2121-d0d6-4fe2-84eb-629592e4e4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report for the atgc prediction\n",
    "print(classification_report(XXXX))\n",
    "\n",
    "# Save the atgc prediction scores for later\n",
    "f1_atgc = XXXX\n",
    "prec_atgc = XXXX\n",
    "rec_atgc = XXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17c1d34-d1fa-4da4-8086-f29537e48748",
   "metadata": {},
   "source": [
    "\n",
    "We see, that our Naive Bayes classifier for the sequence length is pretty good at identifying CD-Box, slightly worse for HACA-Box and pretty low scores for scaRNA. \n",
    "Also the comparison of the different features show huge differences in the sequence features and their accuracy.\n",
    "\n",
    "From these reports we can make out, that HACA-Box has high recall, but lower precision, while scaRNA has very low recall. Missing are now important information if our model has in general a problem to predict a class or is it more a problem for some interconnected classes. Therefore we can use confusion matrices to directly see the true positives and false positives and their predicted label vs. the true label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d521004-038e-4f8a-91f7-5a1824f7d80c",
   "metadata": {},
   "source": [
    "We can use sklearn's `confusion_matrix()` ([Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)). If we add `normalize=\"true\"` the results are normalized over each row. To make it a little prettier, let's plot it as a heatmap, using seaborn again ([Documentation](https://seaborn.pydata.org/generated/seaborn.heatmap.html)). We need one intermediate step to transform the data into a dataframe, such that we can provide the heatmap with labels for the x- and y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ae8a16-a495-4930-882f-dce7741049d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_test, prediction_length, normalize=\"true\")\n",
    "\n",
    "# Turn matrix into a dataframe (necessary for plotting)\n",
    "conf_df = pd.DataFrame(conf_matrix, index=[\"CD-Box\", \"HACA-Box\", \"scaRNA\"], columns=[\"CD-Box\", \"HACA-Box\", \"scaRNA\"])\n",
    "\n",
    "# Plot the heatmap of the confusion\n",
    "sns.heatmap(conf_df, annot=True, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c64f57-fa15-48ee-99ea-c84cce12a830",
   "metadata": {},
   "source": [
    "### Create a classifier combining several sequence features to increase the prediction accuracy\n",
    "\n",
    "Create more `GaussianNB()` classifiers by providing combinations of \"AT/GC ratio\", \"length\" and \"GC_content\". You can think of combining two features like \"length\" and \"ATGC_ratio\"or use all three values. \n",
    "You can access multiple columns at once by writing the column names in a list: `X_train[[\"length\", \"GC_content\"]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bead820b-a1d1-48c1-9daa-8559106feb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split GC_content and length into train and test, make sure you set the random_state to the same number as before\n",
    "X_train_length_gc, X_test_length_gc, Y_train, Y_test = train_test_split(full_df[[\"GC_content\", \"length\"]], full_df[\"type\"], test_size=0.15, random_state=XXXX, stratify=full_df[\"type\"])\n",
    "\n",
    "# create classifier and train using length and GC\n",
    "gnb_length_gc = GaussianNB() \n",
    "gnb_length_gc.fit(X_train_length_gc, Y_train)\n",
    "\n",
    "# generate predictions and output classification report\n",
    "prediction_length_gc = gnb_length_gc.predict(X_test_length_gc) \n",
    "print(classification_report(Y_test, prediction_length_gc))\n",
    "\n",
    "# Save scores for later\n",
    "f1_length_gc = f1_score(Y_test, prediction_length_gc, average=\"weighted\")\n",
    "prec_length_gc = precision_score(Y_test, prediction_length_gc, average=\"weighted\")\n",
    "rec_length_gc = recall_score(Y_test, prediction_length_gc, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47dac22-4b32-402d-ad4a-79e04e613e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the length and atgc data into train and test, don't forget to set the random_state to the same number as before\n",
    "X_train_length_atgc, X_test_length_atgc, Y_train, Y_test = XXXX \n",
    "\n",
    "# create classifier and train using length and atgc\n",
    "gnb_length_atgc = XXXX \n",
    "gnb_length_atgc.fit(XXXX)\n",
    "\n",
    "# generate predictions and print classification report\n",
    "prediction_length_atgc = XXXX \n",
    "print(classification_report(Y_test, prediction_length_atgc))\n",
    "\n",
    "# Save scores for later\n",
    "f1_length_atgc = XXXX\n",
    "prec_length_atgc = XXXX\n",
    "rec_length_atgc = XXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d23a4ac-3b7a-42ec-81eb-bc6e33ac142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split all three measures into train/test\n",
    "X_train_length_atgc_gc, X_test_length_atgc_gc, Y_train, Y_test = train_test_split(full_df[[\"ATGC_ratio\", \"length\", \"GC_content\"]],\n",
    "                                                                                  full_df[\"type\"], test_size=0.15,\n",
    "                                                                                  random_state=XXXX, stratify=full_df[\"type\"])\n",
    "\n",
    "# create classifier and train using all three measures\n",
    "gnb_length_atgc_gc = GaussianNB() \n",
    "gnb_length_atgc_gc.fit(X_train_length_atgc_gc, Y_train)\n",
    "\n",
    "# Predict and print classifcation report\n",
    "prediction_length_atgc_gc = gnb_length_atgc_gc.predict(X_test_length_atgc_gc)\n",
    "print(classification_report(Y_test, prediction_length_atgc_gc))\n",
    "\n",
    "# Save scores for later\n",
    "f1_length_atgc_gc = XXXX\n",
    "prec_length_atgc_gc = XXXX\n",
    "rec_length_atgc_gc = XXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affbd4b9-00c8-4a49-a125-dbabfc7b6049",
   "metadata": {},
   "source": [
    "**Which combination or single sequence feature has the highest accuracy so far? What does this mean for our future classifiers?**\n",
    "\n",
    "Feature selection can often be tricky. It is important to plot the data and experiment with different inputs, to see what features might be useful for the prediction. What input variables do you feed into the model and what is your hypothesis? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6b343f-08e8-4ea2-affe-7c93d426512e",
   "metadata": {},
   "source": [
    "Let's also plot the different scores we saved, so we can compare all models together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f060fd-c238-4dfb-b4ac-c5067f0b0084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict with all the scores\n",
    "dictionary = {\"Accuracy\": [f1_length, f1_gc, f1_atgc, f1_length_gc, f1_length_atgc, f1_length_atgc_gc],\n",
    "              \"Precision\": [prec_length, prec_gc, prec_atgc, prec_length_gc, prec_length_atgc, prec_length_atgc_gc],\n",
    "              \"Recall\": [rec_length, rec_gc, rec_atgc, rec_length_gc, rec_length_atgc, rec_length_atgc_gc],\n",
    "              \"Model\": [\"Length\", \"GC Content\", \"ATGC Ratio\", \"Length + GC\", \"Length + ATGC\", \"Length + GC + ATGC\"]}\n",
    "\n",
    "# Turn into dictionary for plotting\n",
    "df = pd.DataFrame(dictionary)\n",
    "\n",
    "# \"melt\" the dataframe (instead of multiple columns for the scores, we now have one column and a \"variable\" column that indicates which score is in this row)\n",
    "df = pd.melt(df, id_vars=[\"Model\"])\n",
    "\n",
    "# Plot using a barplot\n",
    "plot = sns.barplot(data=df, x=\"variable\", y=\"value\", hue=\"Model\")\n",
    "plt.legend(loc='lower right')\n",
    "plot.set(ylim=(0.3, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3502241-9621-48a1-a71e-164800668390",
   "metadata": {},
   "source": [
    "# Training CNNs to compare the accuracy with our ground truth\n",
    "\n",
    "We already achieve an accuracy of around 67%, but there is still a lot of room for improvements. Deep learning or other, newer ML models can be a better choice for classification tasks where simple models like naive Bayes struggle or vice versa. For this reason in the next notebook we would like to optimize CNNs for our problem and compare it to our ground accuracy of ~67%.\n",
    "\n",
    "## Now go to 2_cnn_classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd8fba-cbde-4d77-9fa9-60001c5385c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
